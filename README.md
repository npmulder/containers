# ğŸ³ Custom Containers

> **Supercharged container images for modern infrastructure**

A curated collection of container images built with security, performance, and simplicity in mind. Each image is crafted to solve real-world deployment challenges while maintaining the highest standards of container best practices.

## ğŸš€ Features

- **ğŸ”’ Security First**: Non-root execution, minimal attack surface, regular vulnerability scanning
- **ğŸ—ï¸ Multi-Architecture**: Native support for AMD64 and ARM64 platforms
- **âš¡ Performance Optimized**: Specialized builds with hardware acceleration support
- **ğŸ¤– Automated**: CI/CD pipeline with automated testing and releases
- **ğŸ“¦ Semantic Versioning**: Predictable releases with proper version management

## ğŸ¯ Available Images

### Ollama with Intel GPU Support
Transform your AI workloads with hardware acceleration out of the box.

```bash
docker run -d \
  --name ollama \
  --device /dev/dri \
  -p 11434:11434 \
  -v ollama:/home/ollama/.ollama \
  ghcr.io/neilmulder/ollama:latest
```

**What makes it special:**
- ğŸ® Intel GPU support with Level Zero and OpenCL
- ğŸ”§ Pre-installed Intel compute runtime libraries
- ğŸš« No init containers required in Kubernetes
- ğŸ” Built-in GPU detection and diagnostics

## ğŸ› ï¸ Quick Start

### Prerequisites
```bash
# Install development tools
mise install

# Or manually install:
# - Docker with Buildx
# - Task (go-task/task)
# - GitHub CLI
# - goss
```

### Build Locally
```bash
# Build any application
task local-build-ollama

# Test the build
task local-build-ollama PLATFORM=linux/amd64
```

### Deploy to Kubernetes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
spec:
  template:
    spec:
      containers:
      - name: ollama
        image: ghcr.io/npmulder/ollama:latest
        resources:
          limits:
            gpu.intel.com/i915: 1
```

## ğŸ—ï¸ Architecture

Built on proven patterns from the home-operations community:

```
containers/
â”œâ”€â”€ apps/              # Individual applications
â”‚   â””â”€â”€ ollama/        # Ollama with Intel GPU
â”œâ”€â”€ include/           # Shared build components
â””â”€â”€ .github/workflows/ # Automated CI/CD
```

Each application follows a consistent structure:
- `Dockerfile` - Multi-stage, security-focused builds
- `entrypoint.sh` - Smart initialization and health checks
- `tests.yaml` - Comprehensive validation with goss
- `docker-bake.hcl` - Advanced build configuration

## ğŸ”¬ Quality Assurance

Every image undergoes rigorous testing:

- **ğŸ§ª Functional Testing**: HTTP endpoints, process validation, file system checks
- **ğŸ›¡ï¸ Security Scanning**: Weekly vulnerability assessments with Trivy and Snyk
- **ğŸ“Š Performance Testing**: Resource usage and startup time validation
- **ğŸ”„ Integration Testing**: End-to-end deployment scenarios

## ğŸš¢ Registry

Images are published to GitHub Container Registry with multiple tagging strategies:

- `ghcr.io/npmulder/ollama:latest` - Latest stable release
- `ghcr.io/npmulder/ollama:sha-abc123` - Specific commit builds
- `ghcr.io/npmulder/ollama:v1.0.0` - Semantic version tags

## ğŸ¤ Contributing

We welcome contributions! Whether it's:

- ğŸ› Bug fixes and improvements
- ğŸ“¦ New application requests
- ğŸ“š Documentation enhancements
- ğŸ”§ Build system optimizations

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by the [home-operations/containers](https://github.com/home-operations/containers) project
- Built with â¤ï¸ for the open-source community
- Special thanks to the Intel GPU compute runtime team

---

<div align="center">
<strong>ğŸ³ Built for the cloud, optimized for performance, secured by design</strong>
</div>